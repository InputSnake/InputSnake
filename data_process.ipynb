{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "short-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import math\n",
    "import random\n",
    "import sparse\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-signature",
   "metadata": {},
   "source": [
    "# Get the CCS Code of each ICD9_CODE in the DIAGNOSES_ICD table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indirect-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_dir = \"../../ccs/hcup_ccs_2015_definitions.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-guest",
   "metadata": {},
   "source": [
    "### ccs_data is loaded as a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "commercial-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ccs_dir, \"r\") as f:\n",
    "    ccs_data = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-lighter",
   "metadata": {},
   "source": [
    "### Expand the \"use_in_benchmark\" and \"id\" to the same length as codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cooked-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ccs_data.keys():\n",
    "    length = len(ccs_data[key][\"codes\"])\n",
    "    ccs_data[key][\"use_in_benchmark\"] = [int(ccs_data[key][\"use_in_benchmark\"])] * length\n",
    "    ccs_data[key][\"id\"] = [ccs_data[key][\"id\"]] * length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "human-packet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ccs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "human-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_diag = pd.read_csv(\"/home/data/datasets/mimic-III/tables/D_ICD_DIAGNOSES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "trained-thread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14567"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_diag.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-waterproof",
   "metadata": {},
   "source": [
    "### Merge the data of each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indoor-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "codes = []\n",
    "use_in_benchmarks = []\n",
    "\n",
    "for key in ccs_data.keys():\n",
    "    ids += ccs_data[key][\"id\"]\n",
    "    codes += ccs_data[key][\"codes\"]\n",
    "    use_in_benchmarks += ccs_data[key][\"use_in_benchmark\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-magic",
   "metadata": {},
   "source": [
    "### Build the DataFrame with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lesbian-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_df = pd.DataFrame({\"ICD9_CODE\": codes, \"CCS\": ids, \"USED\": use_in_benchmarks})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-windsor",
   "metadata": {},
   "source": [
    "### Merge ccs_df and DIAGNOSES_ICD on ICD9_CODE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indie-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_dir = \"../../tables/DIAGNOSES_ICD.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "white-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = pd.read_csv(diag_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vital-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = diag[diag[\"ICD9_CODE\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incredible-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = diag.merge(ccs_df, how=\"left\", on=\"ICD9_CODE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-nirvana",
   "metadata": {},
   "source": [
    "### Drop the CCS Codes which are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "former-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = diag[diag[\"USED\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-direction",
   "metadata": {},
   "source": [
    "### Map the CCS Codes to index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "capable-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ccs_codes = sorted(diag[\"CCS\"].value_counts().index.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "effective-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"INDEX\"] = diag[\"CCS\"].map(lambda x: unique_ccs_codes.index(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-blackjack",
   "metadata": {},
   "source": [
    "# Get the diagnoses multihot label and merge to mortality label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-collapse",
   "metadata": {},
   "source": [
    "### Remove the one HADM_ID to multiple ICU_STAY_ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-lending",
   "metadata": {},
   "source": [
    "read icu table; use drop_duplicates() to remove the illegal HADM_ID; merge label table with icu; drop null HADM_ID; merge diag table; get multi-hot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-panic",
   "metadata": {},
   "source": [
    "### Drop duplicate HADM_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "according-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_dir = \"../../tables/ICUSTAYS.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "distributed-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "icu = pd.read_csv(icu_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "resistant-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "icu = icu.drop_duplicates(subset=[\"HADM_ID\"], keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-reunion",
   "metadata": {},
   "source": [
    "### Merge Mortality label and icu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "received-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_label_dir = \"../../processed/population/mortality_48.0h.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "center-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_label = pd.read_csv(mort_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abroad-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_label.rename(columns={\"ID\": \"ICUSTAY_ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "identical-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_label = pd.merge(mort_label[[\"ICUSTAY_ID\", \"mortality_LABEL\"]], icu[[\"ICUSTAY_ID\", \"HADM_ID\"]], how=\"left\", on=\"ICUSTAY_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-canadian",
   "metadata": {},
   "source": [
    "### Drop the HADM_ID with multiple ICUSTAY_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "incorporated-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_label = mort_label[mort_label[\"HADM_ID\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "assumed-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_label[\"HADM_ID\"] = mort_label[\"HADM_ID\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-enhancement",
   "metadata": {},
   "source": [
    "### Get the CCS index of each ICUSTAY_ID/HADM_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pleased-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_label = pd.merge(mort_label, diag[[\"HADM_ID\", \"INDEX\"]], on=\"HADM_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-deviation",
   "metadata": {},
   "source": [
    "### Drop the ICUSTAY_ID without INDEX. Could be without ICD9_CODE or the ICD9_CODE is not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "permanent-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_label = mort_label[mort_label[\"INDEX\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "norwegian-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_label[\"INDEX\"] = mort_label[\"INDEX\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-advice",
   "metadata": {},
   "source": [
    "### Build the multi-hot label for Diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "private-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_label = mort_label.groupby(\"ICUSTAY_ID\")[\"INDEX\"].apply(lambda x: x.to_numpy()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "proper-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihot(x):\n",
    "    temp = np.zeros(25)\n",
    "    temp[x] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "immune-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_label[\"diagnoses_LABEL\"] = diag_label[\"INDEX\"].map(multihot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-dayton",
   "metadata": {},
   "source": [
    "### Merge the diagnoses label and mortality label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "voluntary-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_mort_label = pd.merge(diag_label[[\"ICUSTAY_ID\", \"diagnoses_LABEL\"]], mort_label[[\"ICUSTAY_ID\", \"mortality_LABEL\"]], on=\"ICUSTAY_ID\", how=\"left\").drop_duplicates(subset=\"ICUSTAY_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-anxiety",
   "metadata": {},
   "source": [
    "# Get the LOS label and merge to diag_mort_label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "closed-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "los = pd.merge(diag_mort_label[\"ICUSTAY_ID\"], icu[[\"ICUSTAY_ID\", \"LOS\"]], on=\"ICUSTAY_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-niagara",
   "metadata": {},
   "source": [
    "### Classify the LOS into 9 categories: 1, 2, 3, 4, 5, 6, 7, 8-14, >14ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "contained-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x):\n",
    "    x = math.floor(x - 2)\n",
    "    if x <= 6:\n",
    "        return x\n",
    "    elif 6 < x <= 13:\n",
    "        return 7\n",
    "    else:\n",
    "        return 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "democratic-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "los[\"INDEX\"] = los[\"LOS\"].map(classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-association",
   "metadata": {},
   "source": [
    "### Build the one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "special-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(x):\n",
    "    temp = np.zeros(9)\n",
    "    temp[x] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "internal-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "los[\"los_LABEL\"] = los[\"INDEX\"].map(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-upgrade",
   "metadata": {},
   "source": [
    "### Merge los to diag_mort_label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "exceptional-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "los_diag_mort_label = pd.merge(los[[\"ICUSTAY_ID\", \"los_LABEL\"]], diag_mort_label, on=\"ICUSTAY_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-haiti",
   "metadata": {},
   "source": [
    "# Split the data into train, val and test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-indonesia",
   "metadata": {},
   "source": [
    "### Get the ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "catholic-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set(los_diag_mort_label[\"ICUSTAY_ID\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "growing-waters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9734\n"
     ]
    }
   ],
   "source": [
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "light-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = set(random.sample(ids, int(len(ids) * 0.7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "diagnostic-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = set(random.sample(ids - train_ids, int(len(ids) * 0.15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "subjective-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = ids - train_ids - val_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-annex",
   "metadata": {},
   "source": [
    "### Get the partition of each id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "altered-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    if x in train_ids:\n",
    "        return \"train\"\n",
    "    elif x in val_ids:\n",
    "        return \"val\"\n",
    "    else:\n",
    "        return \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "further-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "los_diag_mort_label[\"partition\"] = los_diag_mort_label[\"ICUSTAY_ID\"].map(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-contract",
   "metadata": {},
   "source": [
    "## Build the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "objective-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_dir = \"../../processed/features/outcome=Mortality,T=48.0,dt=1.0/X.npz\"\n",
    "time_invariant_dir = \"../../processed/features/outcome=Mortality,T=48.0,dt=1.0/s.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "empirical-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = sparse.load_npz(time_series_dir).todense()\n",
    "time_invariant = sparse.load_npz(time_invariant_dir).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-frequency",
   "metadata": {},
   "source": [
    "### Assume the entries of time_series and time_invariant are corresponding to the entires in mort_label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "filled-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_feats = pd.read_csv(mort_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "higher-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_feats.rename(columns={\"ID\": \"ICUSTAY_ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-pakistan",
   "metadata": {},
   "source": [
    "### Get the features of each ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "muslim-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_feats[\"time_series\"] = [item for item in time_series]\n",
    "id_feats[\"time_invariant\"] = [item for item in time_invariant]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-pregnancy",
   "metadata": {},
   "source": [
    "### Merge to los_diag_mort_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "phantom-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "los_diag_mort_data = pd.merge(los_diag_mort_label, id_feats[[\"ICUSTAY_ID\", \"time_series\", \"time_invariant\"]], on=\"ICUSTAY_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-crawford",
   "metadata": {},
   "source": [
    "# Save the data to hdf5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "unlike-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(df, partition, hdf):\n",
    "    group = hdf.create_group(partition)\n",
    "    for col in df.columns:\n",
    "        data = np.stack(df[col].to_numpy())\n",
    "        group.create_dataset(col, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "studied-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = [\"train\", \"val\", \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "oriented-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = h5py.File(\"data.hdf5\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "individual-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in partitions:\n",
    "    df = los_diag_mort_data[los_diag_mort_data[\"partition\"] == partition]\n",
    "    save(df.drop(columns=\"partition\"), partition, hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "honest-theater",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hdf.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}